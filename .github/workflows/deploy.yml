name: Deploy to Linux Server

on:
  push:
    branches: ["*"]
  pull_request:
    branches: ["*"]

jobs:
  syntax-check:
    name: Syntax check (CSV & JSON)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Check trafic.json syntax
        run: |
          python -m json.tool trafic.json

      - name: Check lines_picto.csv syntax
        run: |
          python -c "import csv; f=open('lines_picto.csv', encoding='utf-8'); next(csv.reader(f, delimiter=';')); f.seek(0); [row for row in csv.reader(f, delimiter=';')]"

      - name: Check logo paths existence
        run: python -c "import csv,os;f=open('lines_picto.csv',encoding='utf-8');r=csv.DictReader(f,delimiter=';');missing=[row['logoPath'] for row in r if not os.path.exists(row['logoPath'].replace('https://clarifygdps.com/hexatransit/',''))];f.close();
          print('Missing logo files ({}):'.format(len(missing)));[print(' -',m) for m in missing];exit(1) if missing else None"

  gtfs-check:
    name: GTFS routes check
    runs-on: ubuntu-latest
    needs: syntax-check
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Check GTFS routes match lines_picto
        run: |
          python - <<'PY'
          import csv, sys, io, urllib.request, zipfile
          from collections import defaultdict

          # Read lines_picto.csv and group line_ids by agency_id
          try:
            f = open('lines_picto.csv', encoding='utf-8')
          except Exception as e:
            print('Failed to open lines_picto.csv:', e)
            sys.exit(1)
          reader = csv.DictReader(f, delimiter=';')
          # Remove BOM from header names if present (some editors add a UTF-8 BOM)
          if reader.fieldnames:
            reader.fieldnames = [fn.lstrip('\ufeff') for fn in reader.fieldnames]
          agencies = defaultdict(set)
          for row in reader:
            aid = row.get('agency_id')
            lid = row.get('line_id')
            if aid and lid:
              agencies[aid].add(lid)
          f.close()
          print(f'Parsed {len(agencies)} agency(ies): {list(agencies.keys())[:50]}')

          errors = []
          total_agencies = len(agencies)
          count = 0
          for agency, line_ids in agencies.items():
            count += 1
            url = f'https://clarifygdps.com/bridge/gtfs/{agency}.zip'
            print(f'[{count}/{total_agencies}] Checking GTFS for agency "{agency}" -> {url}')
            try:
              resp = urllib.request.urlopen(url, timeout=30)
              data = resp.read()
            except Exception as e:
              msg = f'Failed to download {url}: {e}'
              print(f'Agency {agency}: ERROR - {msg}')
              errors.append(msg)
              continue
            try:
              z = zipfile.ZipFile(io.BytesIO(data))
            except Exception as e:
              msg = f'Invalid zip for {agency}: {e}'
              print(f'Agency {agency}: ERROR - {msg}')
              errors.append(msg)
              continue

            namelist = z.namelist()
            # Find a routes.txt (may be in a subfolder)
            rname = None
            for n in namelist:
              if n.endswith('routes.txt'):
                rname = n
                break
            if not rname:
              msg = f'No routes.txt in GTFS for {agency} (found files: {namelist[:10]})'
              print(f'Agency {agency}: ERROR - {msg}')
              errors.append(msg)
              continue

            try:
              with z.open(rname) as rf:
                txt = io.TextIOWrapper(rf, encoding='utf-8', errors='replace')
                routes = list(csv.DictReader(txt))
            except Exception as e:
              msg = f'Failed to read routes.txt for {agency}: {e}'
              print(f'Agency {agency}: ERROR - {msg}')
              errors.append(msg)
              continue

            route_ids = set()
            for r in routes:
              if 'route_id' in r and r['route_id']:
                route_ids.add(r['route_id'])

            # Match only against route_id (do not match on route_short_name)
            missing = sorted([lid for lid in line_ids if lid not in route_ids])
            if missing:
              msg = f'{len(missing)} missing line_id(s) not found in routes.txt: {missing[:20]}'
              print(f'Agency {agency}: ERROR - {msg}')
              errors.append(f'Agency {agency}: {msg}')
            else:
              print(f'Agency {agency}: OK ({len(line_ids)} line_ids matched)')

          # Summary and exit code
          if errors:
            print('\nGTFS verification errors:')
            for e in errors:
              print(' -', e)
            sys.exit(1)
          else:
            print('\nAll GTFS checks passed.')
          PY

  deploy:
    if: github.ref == 'refs/heads/main'
    needs: [syntax-check, gtfs-check]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Set up SSH key
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Add server to known_hosts
        run: |
          ssh-keyscan 217.182.174.221 >> ~/.ssh/known_hosts

      - name: Copy files to server
        run: |
          rsync -avz --delete --exclude='.git*' ./ jouca@217.182.174.221:/var/www/html/hexatransit
        env:
          SSH_AUTH_SOCK: ${{ env.SSH_AUTH_SOCK }}
